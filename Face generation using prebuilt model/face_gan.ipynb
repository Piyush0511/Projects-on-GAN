{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "face_gan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIabOSPhYgTD",
        "colab_type": "text"
      },
      "source": [
        "# Generating High Rez GAN Faces with Google CoLab\n",
        "\n",
        "This notebook demonstrates how to run [NVidia StyleGAN](https://github.com/NVlabs/stylegan) inside of a Google CoLab notebook.  I suggest you use this to generate GAN faces from a pretrained model.  If you try to train your own, you will run into compute limitations of Google CoLab.\n",
        "\n",
        "Make sure to run this code on a GPU instance.  GPU is assumed.\n",
        "\n",
        "This is from my [class on deep learning](  https://www.youtube.com/watch?v=EQ38k6z2aks&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN)\n",
        "\n",
        "[Jeff Heaton](https://www.heatonresearch.com/)\n",
        "\n",
        "# Instructions\n",
        "\n",
        "First, map your G-Drive, this is where your GANs will be written to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv7PBBU7kOkD",
        "colab_type": "code",
        "outputId": "34e537ff-f1eb-4605-c7e6-32c55e8bd9b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zX4LsOo_YstE",
        "colab_type": "text"
      },
      "source": [
        "Next, clone Stylegan from GitHub."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjDcs9Wvhk_6",
        "colab_type": "code",
        "outputId": "a48ca795-0de4-4e10-b26a-88655b329c0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git clone https://github.com/NVlabs/stylegan.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'stylegan' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhGqVIl8Y1m1",
        "colab_type": "text"
      },
      "source": [
        "Verify that Stylegan has been cloned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TQMXLBNjoV5",
        "colab_type": "code",
        "outputId": "093a503a-443b-4056-a835-7ce674bd4f16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!ls /content/stylegan/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "config.py\t     LICENSE.txt\t    README.md\t\t train.py\n",
            "dataset_tool.py      metrics\t\t    run_metrics.py\n",
            "dnnlib\t\t     pretrained_example.py  stylegan-teaser.png\n",
            "generate_figures.py  __pycache__\t    training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zARjPp4rY6vc",
        "colab_type": "text"
      },
      "source": [
        "Add the Stylegan folder to Python so that you can import it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaFXI2RMhmly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, \"/content/stylegan\")\n",
        "\n",
        "import dnnlib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxmjqpxdZFkj",
        "colab_type": "text"
      },
      "source": [
        "The code below is baed on code from NVidia.  This actually generates your images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfN_qgXVi2PU",
        "colab_type": "code",
        "outputId": "d188a1ff-8a77-45b6-b461-9a125a6479e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Copyright (c) 2019, NVIDIA CORPORATION. All rights reserved.\n",
        "#\n",
        "# This work is licensed under the Creative Commons Attribution-NonCommercial\n",
        "# 4.0 International License. To view a copy of this license, visit\n",
        "# http://creativecommons.org/licenses/by-nc/4.0/ or send a letter to\n",
        "# Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.\n",
        "\n",
        "\"\"\"Minimal script for generating an image using pre-trained StyleGAN generator.\"\"\"\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import config\n",
        "\n",
        "def main():\n",
        "    # Initialize TensorFlow.\n",
        "    tflib.init_tf()\n",
        "\n",
        "    # Load pre-trained network.\n",
        "    url = 'https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ' # karras2019stylegan-ffhq-1024x1024.pkl\n",
        "    with dnnlib.util.open_url(url, cache_dir=config.cache_dir) as f:\n",
        "        _G, _D, Gs = pickle.load(f)\n",
        "        # _G = Instantaneous snapshot of the generator. Mainly useful for resuming a previous training run.\n",
        "        # _D = Instantaneous snapshot of the discriminator. Mainly useful for resuming a previous training run.\n",
        "        # Gs = Long-term average of the generator. Yields higher-quality results than the instantaneous snapshot.\n",
        "\n",
        "    # Print network details.\n",
        "    Gs.print_layers()\n",
        "\n",
        "    for qer in range(10):\n",
        "    # Pick latent vector.\n",
        "      rnd = np.random.RandomState()\n",
        "    \n",
        "\n",
        "      latents = rnd.randn(1, Gs.input_shape[1])\n",
        "    \n",
        "    # Generate image.\n",
        "      fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "      images = Gs.run(latents, None, truncation_psi=0.7, randomize_noise=True, output_transform=fmt)\n",
        "\n",
        "    # Save image.f\"train-{cnt}.png\"\n",
        "      os.makedirs(config.result_dir, exist_ok=True)\n",
        "      png_filename = os.path.join(config.result_dir, f'/content/drive/My Drive/ganniv/example-{qer}.png')\n",
        "      PIL.Image.fromarray(images[0], 'RGB').save(png_filename)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Gs                              Params    OutputShape          WeightShape     \n",
            "---                             ---       ---                  ---             \n",
            "latents_in                      -         (?, 512)             -               \n",
            "labels_in                       -         (?, 0)               -               \n",
            "lod                             -         ()                   -               \n",
            "dlatent_avg                     -         (512,)               -               \n",
            "G_mapping/latents_in            -         (?, 512)             -               \n",
            "G_mapping/labels_in             -         (?, 0)               -               \n",
            "G_mapping/PixelNorm             -         (?, 512)             -               \n",
            "G_mapping/Dense0                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense1                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense2                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense3                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense4                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense5                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense6                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense7                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Broadcast             -         (?, 18, 512)         -               \n",
            "G_mapping/dlatents_out          -         (?, 18, 512)         -               \n",
            "Truncation                      -         (?, 18, 512)         -               \n",
            "G_synthesis/dlatents_in         -         (?, 18, 512)         -               \n",
            "G_synthesis/4x4/Const           534528    (?, 512, 4, 4)       (512,)          \n",
            "G_synthesis/4x4/Conv            2885632   (?, 512, 4, 4)       (3, 3, 512, 512)\n",
            "G_synthesis/ToRGB_lod8          1539      (?, 3, 4, 4)         (1, 1, 512, 3)  \n",
            "G_synthesis/8x8/Conv0_up        2885632   (?, 512, 8, 8)       (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Conv1           2885632   (?, 512, 8, 8)       (3, 3, 512, 512)\n",
            "G_synthesis/ToRGB_lod7          1539      (?, 3, 8, 8)         (1, 1, 512, 3)  \n",
            "G_synthesis/Upscale2D           -         (?, 3, 8, 8)         -               \n",
            "G_synthesis/Grow_lod7           -         (?, 3, 8, 8)         -               \n",
            "G_synthesis/16x16/Conv0_up      2885632   (?, 512, 16, 16)     (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Conv1         2885632   (?, 512, 16, 16)     (3, 3, 512, 512)\n",
            "G_synthesis/ToRGB_lod6          1539      (?, 3, 16, 16)       (1, 1, 512, 3)  \n",
            "G_synthesis/Upscale2D_1         -         (?, 3, 16, 16)       -               \n",
            "G_synthesis/Grow_lod6           -         (?, 3, 16, 16)       -               \n",
            "G_synthesis/32x32/Conv0_up      2885632   (?, 512, 32, 32)     (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Conv1         2885632   (?, 512, 32, 32)     (3, 3, 512, 512)\n",
            "G_synthesis/ToRGB_lod5          1539      (?, 3, 32, 32)       (1, 1, 512, 3)  \n",
            "G_synthesis/Upscale2D_2         -         (?, 3, 32, 32)       -               \n",
            "G_synthesis/Grow_lod5           -         (?, 3, 32, 32)       -               \n",
            "G_synthesis/64x64/Conv0_up      1442816   (?, 256, 64, 64)     (3, 3, 512, 256)\n",
            "G_synthesis/64x64/Conv1         852992    (?, 256, 64, 64)     (3, 3, 256, 256)\n",
            "G_synthesis/ToRGB_lod4          771       (?, 3, 64, 64)       (1, 1, 256, 3)  \n",
            "G_synthesis/Upscale2D_3         -         (?, 3, 64, 64)       -               \n",
            "G_synthesis/Grow_lod4           -         (?, 3, 64, 64)       -               \n",
            "G_synthesis/128x128/Conv0_up    426496    (?, 128, 128, 128)   (3, 3, 256, 128)\n",
            "G_synthesis/128x128/Conv1       279040    (?, 128, 128, 128)   (3, 3, 128, 128)\n",
            "G_synthesis/ToRGB_lod3          387       (?, 3, 128, 128)     (1, 1, 128, 3)  \n",
            "G_synthesis/Upscale2D_4         -         (?, 3, 128, 128)     -               \n",
            "G_synthesis/Grow_lod3           -         (?, 3, 128, 128)     -               \n",
            "G_synthesis/256x256/Conv0_up    139520    (?, 64, 256, 256)    (3, 3, 128, 64) \n",
            "G_synthesis/256x256/Conv1       102656    (?, 64, 256, 256)    (3, 3, 64, 64)  \n",
            "G_synthesis/ToRGB_lod2          195       (?, 3, 256, 256)     (1, 1, 64, 3)   \n",
            "G_synthesis/Upscale2D_5         -         (?, 3, 256, 256)     -               \n",
            "G_synthesis/Grow_lod2           -         (?, 3, 256, 256)     -               \n",
            "G_synthesis/512x512/Conv0_up    51328     (?, 32, 512, 512)    (3, 3, 64, 32)  \n",
            "G_synthesis/512x512/Conv1       42112     (?, 32, 512, 512)    (3, 3, 32, 32)  \n",
            "G_synthesis/ToRGB_lod1          99        (?, 3, 512, 512)     (1, 1, 32, 3)   \n",
            "G_synthesis/Upscale2D_6         -         (?, 3, 512, 512)     -               \n",
            "G_synthesis/Grow_lod1           -         (?, 3, 512, 512)     -               \n",
            "G_synthesis/1024x1024/Conv0_up  21056     (?, 16, 1024, 1024)  (3, 3, 32, 16)  \n",
            "G_synthesis/1024x1024/Conv1     18752     (?, 16, 1024, 1024)  (3, 3, 16, 16)  \n",
            "G_synthesis/ToRGB_lod0          51        (?, 3, 1024, 1024)   (1, 1, 16, 3)   \n",
            "G_synthesis/Upscale2D_7         -         (?, 3, 1024, 1024)   -               \n",
            "G_synthesis/Grow_lod0           -         (?, 3, 1024, 1024)   -               \n",
            "G_synthesis/images_out          -         (?, 3, 1024, 1024)   -               \n",
            "G_synthesis/lod                 -         ()                   -               \n",
            "G_synthesis/noise0              -         (1, 1, 4, 4)         -               \n",
            "G_synthesis/noise1              -         (1, 1, 4, 4)         -               \n",
            "G_synthesis/noise2              -         (1, 1, 8, 8)         -               \n",
            "G_synthesis/noise3              -         (1, 1, 8, 8)         -               \n",
            "G_synthesis/noise4              -         (1, 1, 16, 16)       -               \n",
            "G_synthesis/noise5              -         (1, 1, 16, 16)       -               \n",
            "G_synthesis/noise6              -         (1, 1, 32, 32)       -               \n",
            "G_synthesis/noise7              -         (1, 1, 32, 32)       -               \n",
            "G_synthesis/noise8              -         (1, 1, 64, 64)       -               \n",
            "G_synthesis/noise9              -         (1, 1, 64, 64)       -               \n",
            "G_synthesis/noise10             -         (1, 1, 128, 128)     -               \n",
            "G_synthesis/noise11             -         (1, 1, 128, 128)     -               \n",
            "G_synthesis/noise12             -         (1, 1, 256, 256)     -               \n",
            "G_synthesis/noise13             -         (1, 1, 256, 256)     -               \n",
            "G_synthesis/noise14             -         (1, 1, 512, 512)     -               \n",
            "G_synthesis/noise15             -         (1, 1, 512, 512)     -               \n",
            "G_synthesis/noise16             -         (1, 1, 1024, 1024)   -               \n",
            "G_synthesis/noise17             -         (1, 1, 1024, 1024)   -               \n",
            "images_out                      -         (?, 3, 1024, 1024)   -               \n",
            "---                             ---       ---                  ---             \n",
            "Total                           26219627                                       \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzqJGX1Gj_fn",
        "colab_type": "code",
        "outputId": "90a00096-e151-47bb-ad16-40fb546c226c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!ls /content/drive/My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 178A0136.JPG\t    dataset\t   ganniv\n",
            " 178A0197.JPG\t    example1.png  'Getting started.pdf'\n",
            "'Colab Notebooks'   faces_gan\t  'haldi selected'\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}